---
title: "The Shape of Digits"
subtitle: "A Bayesian Topological Data Analytic Approach to Classification of Handwritten Digits"
authors:
  - name: Thomas Reinke
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
    # email: thomas_reinke1@baylor.edu
  - name: Theophilus A. Bediako
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
  - name: Daniel Lim
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
date: today
date-format: "MMMM D, YYYY"
format: 
  revealjs:
    theme: 
      - quarto-assets/baylor-theme.scss
    smaller: false
    scrollable: false
    show-slide-number: all
    toc: false
    toc-depth: 1
    preview-links: true
    slide-number: c/t
    multiplex: false
    embed-resources: true
    auto-animate: true
    #footer: "Thomas Reinke"
bibliography: references.bibtex
lightbox:
  match: auto
  effect: fade
  desc-position: bottom
  loop: true
logo: "quarto-assets/baylor.png"
license: "CC BY-NC"
copyright: 
  holder: Thomas Reinke
  year: 2025
editor: 
  markdown: 
    wrap: 72
fig-width: 15
---

```{r, setup}
#| include: false
#| message: false
library(quarto)
library(knitr)
library(tidyverse)
library(conflicted)
library(janitor)
library(ggtda)
# library(TDAvis)
library(patchwork)
library(gganimate)
library(ggforce)
library(simplextree) 
library(gifski)
library(magick)  
library(ripserr)
library(reshape2)
# remotes::install_github("maroulaslab/BayesTDA") Use this if package ‘BayesTDA’ is not available for this version of R
library(BayesTDA)
library(TDAstats)
library(mvtnorm)
library(kableExtra)
library(plotly)
library(DiagrammeR)
library(transport)
library(TDA)
library(RColorBrewer)
library(Rtsne)
library(keras)
library(furrr)
library(yardstick)
library(caret)
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflicts_prefer(ggtda::geom_simplicial_complex)
conflicted::conflicts_prefer(plotly::layout)
knitr::opts_chunk$set(
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  echo = FALSE,
  tidy.opts = list(width.cutoff = 100),
  tidy = FALSE,
  fig.align = "center"
)
ggplot2::theme_set(ggplot2::theme_minimal())
ggplot2::theme_update(panel.grid.minor = ggplot2::element_blank())

#------------------------------------------------------------#
```

::: {.content-hidden}
$$
{{< include quarto-assets/_macros.tex >}}
$$
:::


```{r load_data}
#--------------------------------------------------------
#----------Load & Preprocess Data------------------------
#--------------------------------------------------------
mnist <- readRDS(file = "mnist_dataset")

train <- mnist$train
test <- mnist$test

train_images <- train$images
train_labels <- as.factor(train$labels)  

test_images <- test$images  
test_labels <- as.factor(test$labels)

train_images <- train_images / 255
test_images <- test_images / 255

train_images_list <- lapply(1:nrow(train_images), function(i) {
  matrix(train_images[i, ], nrow = 28) |> t()
})

test_images_list <- lapply(1:nrow(test_images), function(i) {
  matrix(test_images[i, ], nrow = 28) |> t()
})

plot_digit <- \(image_list = train_images_list, image_index = NULL, image_df = NULL, melted = FALSE){
  if(!melted){
    image_df <- melt(image_list[image_index])
    colnames(image_df) <- c("y", "x", "value")
  }
  ggplot(image_df, aes(x = x, y = y, fill = value)) + 
    geom_raster() +
  scale_fill_gradient(low = "white", high = "black") +
  scale_y_reverse() + 
  coord_equal() +
  theme_void() + 
  theme(legend.position = "none") 
}

# plot_digit(image_index = 8)
# paste0("Label: ", train$labels[8])

binarize_images <- function(images_list, threshold = 0.5) {
  lapply(images_list, function(mat) {
    ifelse(mat < threshold, 0, 1)
  })
}

train_images_binarized <- binarize_images(train_images_list)
test_images_binarized <- binarize_images(test_images_list)

# plot_digit(image_index = 8) + plot_digit(train_images_binarized, image_index = 8)

#------------------------------------------------------------#
```

# Contents

1. [MNIST EDA](#sec-EDA)
1. [Tradiotional ML](#sec-MLMethod)
1. [Proposed Methodology](#sec-PropMethod)
1. [Analysis](#sec-Analysis)
1. [TDA + ML](#sec-TDAML)
1. [Results/Future Work](#sec-Results)
1. [References](#sec-References)


# Exploratory Data Analysis {#sec-EDA}


## Distribution of training labels

```{r dist_labels, fig.dim=c(10,6)}
#--------------------------------------------------------
#----------Distribution of training labels---------------
#--------------------------------------------------------
#first run the qmd file
train_df <- train$images |> as.data.frame()
train_df$labels <- train$labels |> as.factor()

ggplot(train_df, aes(labels, fill = labels))+
  geom_bar()+
  labs(fill = "digit")

```

:::{.notes}
- Around 6000 digits in each class
- No class imbalance
:::

## Pixel Intensity

```{r pixel_intensity, fig.dim=c(10,6)}
#----------------------------------------------------------
#-----------Pixel intensity representation-----------------
#----------------------------------------------------------
# train_df_long <- train_df |>
#   pivot_longer(-labels, names_to  = "covariate", values_to = "intensity")
# saveRDS(train_df_long, "train_df_long.rds")
train_df_long <- readRDS("train_df_long.rds")

ggplot(train_df_long) +
  geom_histogram(
    aes(intensity),
    bins = 30,
    fill = "#2C7FB8",
    color = "white",
    alpha = 0.8
  ) 
# ggplot(train_df_long) +
#   geom_histogram(
#     aes(intensity),
#     bins = 30,
#     fill = "#2C7FB8",
#     color = "white",
#     alpha = 0.8
#   ) +
#   scale_y_log10() +
#   labs(y = "Count (log scale)")

```

## Training Data tSNE Visualization

```{r tnse, fig.dim=c(10,6)}
#------------------------------------------------------------
#----------------distribution of mnist training--------------
#------------------------------------------------------------
#normalized pixel values and apply t-SNE
# tsne_results <- Rtsne(
#   train_images,
#   dim = 2,
#   perplexity = 30,
#   max_iter = 1000
# )
# df_tsne <- tibble(Dim1 = tsne_results$Y[, 1],
#                   Dim2 = tsne_results$Y[, 2],
#                   digit = train_df$labels)
#
# saveRDS(df_tsne, "df_tsne")
df_tsne <- readRDS("df_tsne")
ggplot(df_tsne, aes(Dim1, Dim2, color = digit)) +
  geom_point(alpha = .5)
```

:::{.notes}
- We adopt t-distributed Stochastic Neighbor Embedding(t-SNE) to represent the data in 2D.See [T-SNE Exploration by TusVasMit](https://rpubs.com/TusVasMit/T-SNEExploration) for more details.
:::

# Traditional ML

## Neural networks

:::{.fragment}
Feedforward neural network with structure:
:::

:::{.incremental}
- Input layer: Consists of neurons that receives the input data each neuron in the input layer represents a feature of the input data
- Hidden layer: One or more hidden layers placed between the input and output layers, responsible for capturing complex patterns
- Output layer: Final output of the network; Number of neurons represents the number of digits
:::

## NN with regularization

:::{.incremental}
- Depending on model, \# network weights > size of training data
    - This leads to overfitting
- We considered two approaches to overfitting:
  - Dropout learning: Like RF, randomly removes fraction of units in layer during model fitting
  - Regularization: Impose penalties on parameters like lasso, ridge, etc.
:::


## Specific NN models considered

:::{.fragment}
- NN with dropout regularization
:::
:::{.fragment}
- NN with ridge regularization
:::
:::{.fragment}
- NN with lasso regularization 
:::

## Multinomial logistic regression

:::{.incremental}
- Multinomial logistic regression equivalently represented by NN with no hidden layers
- Output layer with softmax
    - $f_m(X) = Pr(Y = m | X) = \frac{e^{Z_m}}{\sum_\limits{l \in K}e^{Z_l}}$
:::

:::{.notes}
- $m$ is the class label
- $Z_m$ is the output of the model for class $m$
- $X$ is the input data
- $K$ is the set of all class labels
- $l$ is a class label in $K$
:::

## NN Fitting

:::{.incremental}
- Train the network for 30 epochs with a batch size of 128
    - SGD updates weights for each batch
- Images are presented in batches of 128, and SGD updates weights after each batch
- Each epoch processes all 60,000 training images
<!-- - After 30 epochs, the network’s error (loss) is visualized on the left graph -->
<!-- - Accuracy shown on the right graph -->
- Classification correct if largest output value matches target label
:::

:::{.notes}
- SGD is an optimization algorithm used to minimize the loss function by updating the model's weights based on the gradients of the loss with respect to the weights
- This process iteratively adjusts the weights to improve the model's performance on the training data
:::

# Proposed Methodology {#sec-PropMethod}

## TDA Workflow

```{tikz}
%| echo: false

\usetikzlibrary{
    positioning, 
    arrows.meta, 
    shapes.geometric, 
    fit, 
    calc
}

\begin{tikzpicture}[
    % Adjusted node distances for better spacing
    node distance = 1.2cm and 2cm,
    every node/.style={
        draw, 
        thick, 
        rounded corners, 
        align=center, 
        minimum height=1.3cm,
        font=\sffamily
    },
    data/.style={fill=green!20, text width=3cm},
    prior/.style={fill=yellow!30, text width=4cm},
    posterior/.style={fill=blue!20, text width=4cm},
    result/.style={fill=red!20, text width=3.5cm},
    process/.style={text width=4cm},
    arrow/.style={->, >=Stealth, thick},
    connector/.style={draw=none, font=\sffamily\Huge},
    % A dedicated style for labels on arrows (edges)
    edge_label/.style={draw=none, midway, fill=none, font=\sffamily}
]

% == Column 1 & 2: Data and PD Calculation ==
% Position nodes in the first two columns
\node[data] (train) {Train Data \\ (60,000 images)};
\node[process, right=of train] (calc_pd_train) {Calculate Train PDs \\ (for dim0 \& dim1)};

% Increased vertical distance for a clearer separation of train/test paths
\node[data, below=3.75cm of train] (test) {Test Data \\ (10,000 images)};
\node[process, right=of test] (calc_pd_test) {Calculate Test PDs \\ (for dim0 \& dim1)};

% == Column 3: Bayesian Model Training ==
% Position this block relative to the training data processing nodes
\node[process, right=of calc_pd_train] (likelihoods) {Likelihood Surfaces from Train PDs \\ (for digits 0-9)};
%\node[connector, right=of likelihoods] (update_op) {$\otimes$};
\node[connector, right=of likelihoods] (update_op) {$\odot$};
\node[prior, right=of update_op] (priors) {Uninformative Priors \\ (for digits 0-9)};
\node[posterior, below=of update_op] (posteriors) {Posterior Surfaces \\ (for digits 0-9)};

% Bounding box for the Bayesian update process
\node[draw, dashed, inner sep=0.4cm, fit=(priors) (likelihoods) (update_op) (posteriors), label={[font=\sffamily\bfseries]above:Bayesian Update}] (model_box) {};

% == Column 4: Classification ==
% Position the classification node vertically centered between its inputs for a balanced look
\node[process, below=of posteriors] (calc_dist) {Calculate Distances to all Posteriors \\ Distance = $d_{0} + d_{1}$};
\node[result, below=of calc_dist] (classify) {Classify as \\ argmin(Distance)};

% == Arrows ==
% Connect nodes with clearer, non-overlapping paths
\draw[arrow] (train) -- (calc_pd_train);
\draw[arrow] (test) -- (calc_pd_test);

% Bayesian model flow
\draw[arrow] (calc_pd_train) -- (likelihoods);
\draw[arrow] (priors) |- (posteriors);
\draw[arrow] (likelihoods) |- (posteriors);

% Classification flow
% Use |- routing to different anchors (north west and south west) to keep lines clean
\draw[arrow] (posteriors) -- (calc_dist);
\draw[arrow] (calc_pd_test) -- (calc_dist);

% Arrow with a nicely placed label for the distance formula
\draw[arrow] (calc_dist) -- (classify);
    %node[edge_label, right=0.2cm] {Distance = \\ $(1-\lambda)d_{0} + \lambda d_{1}$};
    %node[edge_label, right=0.2cm] {Distance = $d_{0} + d_{1}$};
    
\end{tikzpicture}
```

# Analysis {#sec-Analysis}

## ML Analysis

*Need confusion matrices*
*Need accuracy, precision, recall, f_meas*

```{r ml_results}
#run the Mnist ML method code first, and take results from there
# ml_results <- tibble(
#   method = c("multinomial", "dropout nn", "ridge nn", "lasso no"),
#   accuracy = c(mlogit_acc, nn_dropout_accu, nn_ridge_accu, nn_lasso_accu)
# )
# saveRDS(ml_results, "ml_results")

ml_results <- readRDS("ml_results") #still a tibble so easy to edit

ml_results |> 
  kable(digits = 4)
```

## Confusion matrix Heatmap - NN dropout
```{r}
## ggplot function to represent the heatmap
cm_ggplot <- function(conf_mat, type) {
  cm_df <- as.data.frame(conf_mat$table)
  ggplot(cm_df, aes(Prediction, Reference, fill = Freq)) +
    geom_tile(color = "white") +
    geom_text(aes(label = Freq), color = "black", size = 4) +
    scale_fill_gradient(low = "white", high = "steelblue") +
    labs(
      title = paste("Confusion matrix heatmap - ", type),
      x = "Predicted label",
      y = "True label",
      fill = "Count"
    )
}
nn_dropout_conf_mat <- readRDS("nn_dropout_conf_mat")
cm_ggplot(nn_dropout_conf_mat, type = "nn_dropout")

```

## Proposed Method Analysis

```{r post_digit_plot0, fig.dim=c(10,6)}
posterior_list_dim0 <- readRDS("btda/posterior_list_dim0.rds")
posterior_dim0_df <- posterior_list_dim0 |>
  set_names(0:9) |>
  list_rbind(names_to = "digit")

ggplot(posterior_dim0_df, aes(x = birth, y = persistence, fill = intensity)) +
  geom_raster() +
  facet_wrap(~digit, ncol = 5) +
  scale_fill_viridis_c(option = "magma") +
  labs(
    title = "Posterior Densities for Digit Components (Dimension 0)",
    x = "Birth",
    y = "Persistence",
    fill = "Intensity"
  ) +
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))
```

## Proposed Method Analysis

```{r post_digit_plot1, fig.dim=c(10,6)}
posterior_list_dim1 <- readRDS("btda/posterior_list_dim1.rds")
posterior_dim1_df <- posterior_list_dim1 |>
  set_names(0:9) |>
  list_rbind(names_to = "digit")

ggplot(posterior_dim1_df, aes(x = birth, y = persistence, fill = intensity)) +
  geom_raster() +
  facet_wrap(~digit, ncol = 5) +
  scale_fill_viridis_c(option = "magma") +
  labs(
    title = "Posterior Densities for Digit Loops (Dimension 1)",
    x = "Birth",
    y = "Persistence",
    fill = "Intensity"
  ) +
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))
```

## Proposed Method Analysis

```{r tda01confmatrix, fig.dim=c(10,6)}

full_tda_01_results <- readRDS("btda/full_tda_01_results.rds")

conf_matrix <- table(
  true_label = full_tda_01_results$true_label,
  predicted_label = full_tda_01_results$predicted_label
)

as.data.frame.matrix(conf_matrix) %>%
  mutate(true_label = fct_rev(rownames(.))) |>
  pivot_longer(
    cols = -true_label,
    names_to = "predicted_label",
    values_to = "count"
  ) |>
  # Add a column to determine text color based on the background
  mutate(text_color = if_else(count < 450, "black", "white")) |>
  ggplot(aes(x = predicted_label, y = true_label, fill = count)) +
  geom_tile(color = "gray50", linewidth = 0.5) +
  # Map the new text_color column to the color aesthetic
  geom_text(aes(label = count, color = text_color), size = 3.5, fontface = "bold") +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  # Manually set the colors and remove the unnecessary legend
  scale_color_manual(values = c("black" = "black", "white" = "white"), guide = "none") +
  coord_fixed() +
  theme_minimal(base_size = 12) +
  labs(
    x = "Predicted Label",
    y = "True Label",
    fill = "Count"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    axis.text.y = element_text(face = "bold"),
    panel.grid = element_blank()
  )

# accuracy <- mean(full_results$true_label == full_results$predicted_label, na.rm = TRUE)

```

## Proposed Method Analysis

```{r tda01metrics}
multi_metrics <- metric_set(
  yardstick::accuracy, 
  yardstick::precision, 
  yardstick::recall, 
  yardstick::f_meas
)

# Now this will work correctly
results_for_metrics <- full_tda_01_results |>
  select(true_label, predicted_label) |>
  mutate(
    true_label = factor(true_label, levels = 0:9),
    predicted_label = factor(predicted_label, levels = 0:9)
  )

multi_metrics(results_for_metrics, truth = true_label, estimate = predicted_label) |> 
  janitor::clean_names() |>
  kable()
```

# TDA + ML {#sec-TDAML}

## About Filtering

## Analysis

```{r loadallfeatures}
all_features_train_data <- readRDS("rdss/all_features_train_data.rds")
all_features_test_data <- readRDS("rdss/all_features_test_data.rds")
all_features_rf_model <- readRDS("rdss/all_features_rf_model.rds")
all_features_svm_model<- readRDS("rdss/all_features_svm_model.rds")
```

```{r modelcomparison, fig.dim=c(10,6)}
model_comparison <- resamples(list(RandomForest = all_features_rf_model, SVM = all_features_svm_model))
# dotplot(model_comparison,
#   scales = list(x = list(rot = 45)))
tidy_comparison <- model_comparison$values |>
  pivot_longer(
    # Exclude the 'Resample' column from being pivoted
    cols = -Resample,
    names_to = "key",
    values_to = "value"
  ) |>
  # This part remains the same
  separate(key, into = c("Model", "Metric"), sep = "~")

# 2. Create the dot plot with ggplot2
ggplot(tidy_comparison, aes(x = value, y = Model, color = Model)) +
  # Make points larger and add transparency
  geom_point(size = 4, alpha = 0.2) +
  # Use a nice, colorblind-friendly color palette
  scale_color_brewer(palette = "Set2") +
  # Ensure the x-axis doesn't extend unnecessarily far
  scale_x_continuous(limits = c(NA, 1.0)) +
  facet_wrap(~ Metric, ncol = 4) +
  labs(
    x = "Metric Value",
    y = NULL,
    color = "Model Type"
  ) +
  theme_light(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 18, margin = margin(b = 5)),
    plot.subtitle = element_text(size = 13, margin = margin(b = 15)),
    strip.text = element_text(face = "bold", size = 10, color = "white"),
    strip.background = element_rect(fill = "#525252", color = "white"),
    legend.position = "bottom",
    panel.grid.major.y = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  # Add this line to control legend aesthetics
  guides(color = guide_legend(override.aes = list(alpha = 1)))
```

:::{.notes}
* **Accuracy**: The proportion of all predictions that were correct. It's a great starting point but can be misleading for imbalanced datasets.
    * *Formula*: $(TP + TN) / (TP + TN + FP + FN)$

* **Balanced Accuracy**: The average of Sensitivity and Specificity. It provides a more robust measure when classes are imbalanced by giving equal importance to both positive and negative classes.
    * *Formula*: $(Sensitivity + Specificity) / 2$

* **Sensitivity (Recall or True Positive Rate)**: Answers: "Of all the actual positive cases, how many did we correctly identify?" High sensitivity is crucial when you cannot afford to miss a positive case (e.g., disease screening).
    * *Formula*: $TP / (TP + FN)$

* **Specificity (True Negative Rate)**: Answers: "Of all the actual negative cases, how many did we correctly identify?" High specificity is important when a false positive is very costly.
    * *Formula*: $TN / (TN + FP)$

* **Precision (Positive Predictive Value)**: Answers: "Of all the cases we predicted as positive, how many were actually positive?" High precision matters when the cost of acting on a false positive is high.
    * *Formula*: $TP / (TP + FP)$

* **Negative Predictive Value (NPV)**: Answers: "Of all the cases we predicted as negative, how many were actually negative?" It's the counterpart to Precision.
    * *Formula*: $TN / (TN + FN)$

* **F1 Score**: The harmonic mean of Precision and Sensitivity. It provides a single score that balances the concerns of both metrics, making it useful when both false positives and false negatives are important to minimize.
    * *Formula*: $2 \times (Precision \times Sensitivity) / (Precision + Sensitivity)$

* **Kappa (Cohen's Kappa)**: Measures the agreement between the model's predictions and the actual labels, corrected for the probability of agreement occurring by chance. A score of 1 indicates perfect agreement, 0 indicates agreement equivalent to random chance, and negative values indicate agreement worse than random.

* **Detection Rate**: The proportion of the entire dataset that consists of true positives. It's less commonly used than accuracy but gives a sense of how often the positive case is found in the population.
    * *Formula*: $TP / (TP + TN + FP + FN)$
:::

## Analysis

```{r allfeaturesheatmap, fig.dim=c(10,6)}
test_indices <- 1:10000
predictions <- predict(all_features_svm_model, newdata = all_features_test_data)
results <- tibble(
  true_label = factor(mnist$test$labels[test_indices]),
  predicted_label = predictions
)

conf_matrix_tda_full <- table(
  true_label = results$true_label,
  predicted_label = results$predicted_label
)

as.data.frame.matrix(conf_matrix_tda_full) %>%
  mutate(true_label = fct_rev(rownames(.))) |>
  pivot_longer(
    cols = -true_label,
    names_to = "predicted_label",
    values_to = "count"
  ) |>
  # Add a column to determine text color based on the background
  mutate(text_color = if_else(count < 450, "black", "white")) |>
  ggplot(aes(x = predicted_label, y = true_label, fill = count)) +
  geom_tile(color = "gray50", linewidth = 0.5) +
  # Map the new text_color column to the color aesthetic
  geom_text(aes(label = count, color = text_color), size = 3.5, fontface = "bold") +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  # Manually set the colors and remove the unnecessary legend
  scale_color_manual(values = c("black" = "black", "white" = "white"), guide = "none") +
  coord_fixed() +
  theme_minimal(base_size = 12) +
  labs(
    x = "Predicted Label",
    y = "True Label",
    fill = "Count"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, face = "bold"),
    axis.text.y = element_text(face = "bold"),
    panel.grid = element_blank()
  )

# final_accuracy <- mean(results$true_label == results$predicted_label, na.rm = TRUE)
# print(paste("Final Test Set Accuracy (Random Forest):", scales::percent(final_accuracy, accuracy = 0.1)))
```

## Analysis

```{r varimportance, fig.dim=c(10,6)}
rf_model_importance <- varImp(all_features_rf_model, scale = TRUE)
svm_model_importance <- filterVarImp(
  x = all_features_train_data[, -which(names(all_features_train_data) == "label")],
  y = all_features_train_data$label
)

rf_plot <- rf_model_importance$importance |>
  as.data.frame() %>%
  mutate(variable = rownames(.)) |>
  pivot_longer(
    cols = -variable,
    names_to = "class",
    values_to = "importance"
  ) |>
  mutate(
    importance = (importance - min(importance)) / (max(importance) - min(importance))
  ) |>
  mutate(variable = fct_reorder(variable, importance, .fun = max, .desc = TRUE)) |>
  ggplot(aes(x = class, y = variable, fill = importance)) +
  geom_tile(color = "white", linewidth = 0.4) +
  scale_fill_viridis_c(
    option = "magma", 
    direction = -1,
    limits = c(0, 1)
  ) +
  labs(
    x = "Class",
    y = "Variable",
    fill = "Importance",
    title = "Random Forest Variable Importance"
  ) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

svm_plot <- as.data.frame(svm_model_importance) %>%
  mutate(variable = rownames(.)) |>
  pivot_longer(
    cols = -variable,
    names_to = "class",
    values_to = "importance"
  ) |>
  mutate(
    importance = (importance - min(importance)) / (max(importance) - min(importance))
  ) |>
  mutate(
    variable = fct_reorder(variable, importance, .fun = max, .desc = TRUE),
    class = gsub("X", "", class)
    ) |>
  ggplot(aes(x = class, y = variable, fill = importance)) +
  geom_tile(color = "white", linewidth = 0.4) +
  scale_fill_viridis_c(option = "magma", direction = -1) +
  labs(
    x = "Class",
    y = NULL, 
    fill = "Importance",
    title = "SVM Variable Importance"
  ) +
  theme_minimal(base_size = 12) +
  theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      axis.text.y = element_blank() 
      )

rf_plot + svm_plot + 
  plot_layout(guides = 'collect')

```

# Results/Future Work {#sec-Results}



## ML + TDA Results

# References {#sec-References}

## References

::: {#refs .smaller}
:::


