---
title: "The Shape of Digits"
subtitle: "A Bayesian Topological Data Analytic Approach to Classification of Handwritten Digits"
date: today
date-format: "MMMM D, YYYY"
authors:
  - name: Thomas Reinke
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
    # email: thomas_reinke1@baylor.edu
  - name: Theophilus A. Bediako
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
  - name: Daniel Lim
    affiliation: 
      - name: Baylor University
        department: Statistical Science
        # city: Waco
        # state: TX
        # country: US
        url: https://www.baylor.edu
format: 
  pdf:
    toc: true
    number-sections: true
    toc-depth: 2
    number-depth: 3
    colorlinks: true
    fontsize: 11pt
    geometry: 
      - top=20mm
      - left=20mm
editor: 
  markdown: 
    wrap: 72
bibliography: references.bibtex
license: "CC BY-NC"
copyright: 
  holder: Thomas Reinke
  year: 2025
header-includes:
  - \definecolor{darkgreen}{HTML}{006400}  
# include-in-header:
#       - text: |
#           /usepackage{amsmath}
---

```{r, setup}
#| include: false
#| message: false
library(quarto)
library(knitr)
library(tidyverse)
library(conflicted)
library(janitor)
library(ggtda)
# library(TDAvis)
library(patchwork)
library(gganimate)
library(ggforce)
library(simplextree) 
library(gifski)
library(magick)  
library(ripserr)
library(reshape2)
# remotes::install_github("maroulaslab/BayesTDA") Use this if package ‘BayesTDA’ is not available for this version of R
library(BayesTDA)
library(TDAstats)
library(mvtnorm)
library(kableExtra)
library(plotly)
library(DiagrammeR)
library(transport)
library(TDA)
library(RColorBrewer)
library(Rtsne)
library(keras)
library(furrr)
library(yardstick)
library(caret)
library(imager)
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflicts_prefer(ggtda::geom_simplicial_complex)
conflicted::conflicts_prefer(plotly::layout)
conflicts_prefer(magrittr::set_names)
knitr::opts_chunk$set(
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  echo = FALSE,
  tidy.opts = list(width.cutoff = 100),
  tidy = FALSE,
  fig.align = "center"
)
ggplot2::theme_set(ggplot2::theme_minimal())
ggplot2::theme_update(panel.grid.minor = ggplot2::element_blank())

#------------------------------------------------------------#
```

::: {.content-hidden}
$$
{{< include quarto-assets/_macros.tex >}}
$$
:::

```{r load_data}
#--------------------------------------------------------
#----------Load & Preprocess Data------------------------
#--------------------------------------------------------
mnist <- readRDS(file = "mnist_dataset")

train <- mnist$train
test <- mnist$test

train_images <- train$images
train_labels <- as.factor(train$labels)  

test_images <- test$images  
test_labels <- as.factor(test$labels)

train_images <- train_images / 255
test_images <- test_images / 255

train_images_list <- lapply(1:nrow(train_images), function(i) {
  matrix(train_images[i, ], nrow = 28) |> t()
})

test_images_list <- lapply(1:nrow(test_images), function(i) {
  matrix(test_images[i, ], nrow = 28) |> t()
})

plot_digit <- \(image_list = train_images_list, image_index = NULL, image_df = NULL, melted = FALSE){
  if(!melted){
    image_df <- melt(image_list[image_index])
    colnames(image_df) <- c("y", "x", "value")
  }
  ggplot(image_df, aes(x = x, y = y, fill = value)) + 
    geom_raster() +
  scale_fill_gradient(low = "white", high = "black") +
  scale_y_reverse() + 
  coord_equal() +
  theme_void() + 
  theme(legend.position = "none") 
}

# plot_digit(image_index = 8)
# paste0("Label: ", train$labels[8])

binarize_images <- function(images_list, threshold = 0.5) {
  lapply(images_list, function(mat) {
    ifelse(mat < threshold, 0, 1)
  })
}

train_images_binarized <- binarize_images(train_images_list)
test_images_binarized <- binarize_images(test_images_list)

# plot_digit(image_index = 8) + plot_digit(train_images_binarized, image_index = 8)

#------------------------------------------------------------#
```

\newpage

# Abstract 

<!-- *A brief overview of the paper.* -->

*This paper ...*

# Introduction 

<!-- *Describes the motivation of this work and outlines the rest of the paper.* -->

The motivation for this work was to compare and examine how dimension reduction via topological data analysis can be used with machine learning and classification models. Algebraic topologist, Gunnar Carlsson, has a quote, "Data has shape, shape has meaning, and meaning brings value." The work in this paper follows this idea, that if there is inherent structure present in data, it can be exploited to aid in modeling. 

The Modified National Institute of Standards and Technology database is a set of handwritten digits that is frequently used to train and test image processing models. Our goal is to classify handwritten digits to their correct numeric label. We compared model performance primarily on accuracy, and secondly on the number of features or predictors. First, we want to build an accurate model that can discriminate between digits. Similar to the idea of parsimony in model selection, if two models have comparable accuracy, we will favor the model trained on fewer features. We also consider the ability of TDA-based models to assess the importance of individual predictors, providing insights into which features most influence MNIST classification


# Background and Related Work

<!-- *Describes what other researchers in the same area have done, and how they perhaps could be improved.* --> 

## MNIST

The development of the MNIST dataset stems from early efforts in optical character recognition (OCR), a field of automating the processing of handwritten information like postal codes and census forms. Its lineage can be traced back to the late 1980s with the creation of the USPS database, a collection of 16×16 grayscale images of handwritten zip codes used to train the LeNet neural network. During the same period, the National Institute of Standards and Technology (NIST) was developing its own Special Databases for OCR research, sourcing images from census forms and high-school student samples. One such collection, SD-7, released in 1992, would later form a core part of the MNIST test set.

Challenges in generalizing models across these different datasets, highlighted during a 1992 NIST/Census Bureau competition, revealed biases within the original NIST data. To address these issues, the MNIST database was created in 1994, providing a cleaner, more standardized benchmark for the machine learning community. The dataset led to the development of several modern variations. These include EMNIST (2017), which extended the character set to include letters; QMNIST (2019), which restored the complete original test set; and Fashion MNIST (2017), a drop-in replacement featuring images of clothing items.

## Related Work

Topological Data Analysis is a technique for extracting structural features from datasets, proving effective in classification tasks across various domains. Work in this area includes that of Nicolau et al., who successfully used a topology-based approach to identify a distinct subgroup of breast cancers with excellent survival rates, demonstrating the method's ability to uncover patterns invisible to other methods [@Nicolau2011]. Researchers have developed more generalized TDA-based classification methods, applying them to problems involving multiple measurements and other complex data structures [@DBLP:journals/corr/abs-1904-02971; @DBLP:journals/corr/abs-2102-03709].

Many traditional machine learning models have been successfully applied to MNIST [@yeboah2025classification], but it has also been a subject of interest for topological methods. Garin and Tauzin provide a "Topological 'Reading' Lesson" by applying TDA specifically to classify MNIST digits, showing that topological features can serve as effective predictors [@DBLP:journals/corr/abs-1910-08345].

We try an integration of a Bayesian framework to the TDA methodology. This is inspired by the Bayesian framework for persistent homology by Maroulas et al. [@Maroulas2020-sp]. Here, we can quantify uncertainty in topological features, in an attempt to increase the predictive power of TDA-based classification models.

# Methodology 

<!-- *Describes what is the approach taken in this paper.* -->

## Traditional Machine Learning

In order to evaluate the value added by TDA-based methods, it is essential to benchmark them against well-established approaches. We consider a range of traditional machine learning (ML) methods, including neural networks with different regularization schemes and classical multinomial logistic regression. Neural networks can overfit, especially on high-dimensional data such as images. Regularization techniques, like dropout, ridge, and lasso help reduce overfitting, and ensure that the network captures meaningful patterns rather than noise.

### Neural Networks

The neural network framework considered in this project is the feedforward neural network. It is one of the most widely used architectures for supervised learning. In a feedforward network, information flows in a single direction—from the input layer, through one or more hidden layers, to the output layer—without cycles or feedback connections. The input layer consists of neurons corresponding to the features of the data. One or more hidden layers are placed between the input and output layers, enabling the network to learn complex and non-linear patterns. Finally, the output layer produces the classification results, with the number of neurons equal to the number of digit classes.

#### Dropout

Dropout is a regularization method that randomly turns off a fraction of neurons during training. This helps the network avoid relying too much on any single neuron and encourages it to learn more general patterns.

#### Ridge

In NN ridge regularization, a penalty proportional to the square of the weights is added to the loss function. This shrinks large weights while keeping most parameters nonzero.

#### Lasso

Lasso regularization penalizes the absolute values of weights, encouraging sparsity in the network. The lasso NN forces many weights towards zero, effectively performing feature selection among pixel intensities.

#### Multinomial Logistic Regression as ML

Multinomial logistic regression, also known as softmax regression, provides a linear baseline for multi-class classification. It is implemented as a single dense layer with softmax activation[@James2013]. Table 1 provides a summary of the model architecture.

### Table 1. Model architectures

| Model                         | Hidden Layers (units) | Activation Functions         | Regularization             | Output Layer |
|-------------------------------|---------------------|-----------------------------|----------------------------   |--------------|
| **Multinomial**               | None                | –                           | None                          | 10           |
| **Dropout NN**                | 256, 128            | ReLU (hidden), Softmax (out)| Dropout (0.4, 0.3)            | 10           |
| **Ridge NN (L2)**             | 256, 128            | ReLU (hidden), Softmax (out)| L2 penalty $(\lambda = 0.01)$ | 10           |
| **Lasso NN (L1)**             | 256, 128            | ReLU (hidden), Softmax (out)| L1 penalty $(\lambda = 0.01)$ | 10           |

All models were trained under identical conditions—30 epochs, batch size of 128, and a validation split of 0.2. This uniform training setup allows for a fair comparison of traditional machine learning methods.

## Our Bayes TDA Methodology

Our methodology can be summarized in this flowchart, where the 'Bayesian update' comes from A Bayesian framework for persistent homology.

```{tikz}
%| echo: false

\usetikzlibrary{
    positioning, 
    arrows.meta, 
    shapes.geometric, 
    fit, 
    calc
}

\begin{tikzpicture}[
    % Adjusted node distances for better spacing
    node distance = 1.2cm and 2cm,
    every node/.style={
        draw, 
        thick, 
        rounded corners, 
        align=center, 
        minimum height=1.3cm,
        font=\sffamily
    },
    data/.style={fill=green!20, text width=3cm},
    prior/.style={fill=yellow!30, text width=4cm},
    posterior/.style={fill=blue!20, text width=4cm},
    result/.style={fill=red!20, text width=3.5cm},
    process/.style={text width=4cm},
    arrow/.style={->, >=Stealth, thick},
    connector/.style={draw=none, font=\sffamily\Huge},
    % A dedicated style for labels on arrows (edges)
    edge_label/.style={draw=none, midway, fill=none, font=\sffamily}
]

% == Column 1 & 2: Data and PD Calculation ==
% Position nodes in the first two columns
\node[data] (train) {Train Data \\ (60,000 images)};
\node[process, right=of train] (calc_pd_train) {Calculate Train PDs \\ (for dim0 \& dim1)};

% Increased vertical distance for a clearer separation of train/test paths
\node[data, below=3.75cm of train] (test) {Test Data \\ (10,000 images)};
\node[process, right=of test] (calc_pd_test) {Calculate Test PDs \\ (for dim0 \& dim1)};

% == Column 3: Bayesian Model Training ==
% Position this block relative to the training data processing nodes
\node[process, right=of calc_pd_train] (likelihoods) {Likelihood Surfaces from Train PDs \\ (for digits 0-9)};
%\node[connector, right=of likelihoods] (update_op) {$\otimes$};
\node[connector, right=of likelihoods] (update_op) {$\odot$};
\node[prior, right=of update_op] (priors) {Uninformative Priors \\ (for digits 0-9)};
\node[posterior, below=of update_op] (posteriors) {Posterior Surfaces \\ (for digits 0-9)};

% Bounding box for the Bayesian update process
\node[draw, dashed, inner sep=0.4cm, fit=(priors) (likelihoods) (update_op) (posteriors), label={[font=\sffamily\bfseries]above:Bayesian Update}] (model_box) {};

% == Column 4: Classification ==
% Position the classification node vertically centered between its inputs for a balanced look
\node[process, below=of posteriors] (calc_dist) {Calculate Distances to all Posteriors \\ Distance = $d_{0} + d_{1}$};
\node[result, below=of calc_dist] (classify) {Classify as \\ argmin(Distance)};

% == Arrows ==
% Connect nodes with clearer, non-overlapping paths
\draw[arrow] (train) -- (calc_pd_train);
\draw[arrow] (test) -- (calc_pd_test);

% Bayesian model flow
\draw[arrow] (calc_pd_train) -- (likelihoods);
\draw[arrow] (priors) |- (posteriors);
\draw[arrow] (likelihoods) |- (posteriors);

% Classification flow
% Use |- routing to different anchors (north west and south west) to keep lines clean
\draw[arrow] (posteriors) -- (calc_dist);
\draw[arrow] (calc_pd_test) -- (calc_dist);

% Arrow with a nicely placed label for the distance formula
\draw[arrow] (calc_dist) -- (classify);
    %node[edge_label, right=0.2cm] {Distance = \\ $(1-\lambda)d_{0} + \lambda d_{1}$};
    %node[edge_label, right=0.2cm] {Distance = $d_{0} + d_{1}$};
    
\end{tikzpicture}
```

### Cubical Complexes & Persistent Homology

<!-- *Simplices* -> *complexes*(typically veitoris rips, but here cubical) -> *filtration* -> *persistence diagrams* -->

For our methodology, we need to get from an image to a persistence diagram. A 2-dimension image is a map $\mathcal{I}: I \subseteq \mathbb{Z}^2 \xrightarrow{} \mathbb{R}$. An element $v \in I$ is a pixel, and has value $\mathcal{I}(v)$, which is the intensity. We can binarize an image by the map $\mathcal{B}: I \subseteq \mathbb{Z}^2 \xrightarrow{} \{0, 1\}$. With data from a point cloud, we typically build simplicial complexes, but with our data from an image, we will build a cubical complex. Pixels are represented by a $d-cube$, including its faces. With the image represented by a cubical complex $K$, we build a filtration, which is a sequence of nested subcomplexes, using the image's grayscale values. We do this with a series of sublevel sets:

$$
K_i := \{\sigma \in K | I(\sigma) \leq i\}
$$

Essentially if a pixel has an intensity less than $i$, the cube representing it is included in the corresponding complex. After applying persistent homology to this filtration, the birth and death 'times' of topological features are tracked across the intensity levels. The persistence diagram $D$, is a multiset, $(b, d, k)$, where each point is a homological feature with dimension $k$, born at intensity $b$, and dies at intensity $d$. Persistence is the length of time a feature lasts, $d - b$. In our case, we can only consider $k=0$, connected components, and $k=1$, loops/one dimension holes. An example persistence diagram is show below of 40 points sampled from a circle. 

```{r expersistence, fig.dim=c(6,3)}
# example persistence diagram

set.seed(5926720)

df <- tdaunif::sample_circle(n = 40L, sd = .05)
colnames(df) <- c("x", "y")
df |> ripserr::vietoris_rips() |>
  ggplot() +
  ggtda::stat_persistence(
    aes(start = birth, end = death,
        color = factor(dimension), shape = factor(dimension)),
    size = 2.5,
    alpha = .75
  ) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", alpha = 0.6) +
  scale_color_viridis_d(end = .7, name = "Dimension") +
  scale_shape_discrete(name = "Dimension") +
  labs(title = "Persistence Diagram") + 
  theme_minimal()

```

From this process we are able to go from an image to a cubical complex to a filtration to a persistence diagram.
 
### Marked Poisson Point Process

<!-- represent persistence diagram as ppp -->

A Poisson Point Process $\Pi$ allows us to model a collection of random points $\{x_1, \ldots, x_n\}$ in a space $\mathbb{X}$, with an intensity measure $\Lambda$. The number of points $N$, is a random variable and follows a Poisson distribution, with mean $\mu = \Lambda(\mathbb{X})$. For a region $A \subseteq X$, $\Lambda(A) = \mathbb{E}[|\Pi \cap A|]$. The mark of each point, $m$, comes from a space $\mathbb{M}$, in our case, the marks will be the dimension $k$. We first have our set of locations $\{x_i\}$, then for each $x_i$, a mark $m_i$ is drawn conditionally & independently from a kernel $\ell(x_i, \cdot)$. 

### Bayes Update & Guassian representation

Now we wish to incorporate a Bayesian framework to these persistence diagrams represented as point processes. Here we use the tilted representation of the diagram, so instead of $(b, d)$, we use $(b, d-b)$ for a persistence diagram $D$. 

The first part we model is the latent or 'true' underlying persistence diagram $D_x$; we model it by the intensity $\lambda_{D_x}(x)$. $D_x$ is decomposed into two independent parts. $D_{XO}$ are the points that can be observed with probability $\alpha(x)$: $\color{blue}{\alpha(x) \lambda_{\mathcal{D}_X}(x)}$. The second part is for points that are missed or not observed: $\color{red}{(1-\alpha(x)) \lambda_{\mathcal{D}_X}(x)}$.

The second part we model is the observed persistence diagram $D_Y$, also two components. $D_{YO}$ are the points generated from $D_{XO}$, which forms the pair $(\mathcal{D}_{XO}, \mathcal{D}_{YO})$. The connection is via the kernel $\color{brown}{\ell(y|x)}$. It gives the probability density of observing $y \in \mathcal{D}_{YO}$ given a latent point $x \in \mathcal{D}_{XO}$. The other component is that the points arise from noise: $\color{darkgreen}{\lambda_{\mathcal{D}_{YS}}(y)}$.

Now we bring the two parts together. The posterior intensity $\lambda_{\mathcal{D}_X | D_{Y^{1:m}}}(x)$ for the latent PD $\mathcal{D}_X$, given $m$ independent observed PDs $D_{Y^1}, \dots, D_{Y^m}$.
Let $D_{Y^{1:m}} = \cup_{i=1}^m D_{Y^i}$. The posterior intensity is:

$$
\lambda_{\mathcal{D}_X | D_{Y^{1:m}}}(x) = \underbrace{\color{red}{(1 - \alpha(x))\lambda_{\mathcal{D}_X}(x)}}_{\text{Prior Vanished Part}} + \underbrace{\frac{1}{m} \alpha(x) \sum_{i=1}^m \sum_{y \in D_{Y^i}} \frac{ \color{brown}{\ell(y|x)}\color{blue}{ \lambda_{\mathcal{D}_X}(x)}}{\color{darkgreen}{\lambda_{\mathcal{D}_{Y_S}}(y)} + \color{blue}{\int_{\mathbb{W}} \ell(y|u) \alpha(u) \lambda_{\mathcal{D}_X}(u) du}}}_{\text{Update from Observed Points } y} \quad \text{a.s.}
$$

Without going into all of details, Maroulas achieves this is computationally using Gaussian mixtures for $\color{blue}\lambda_{D_x}$, $\color{brown}{\ell(y|x)}$, and $\color{darkgreen}{\lambda_{\mathcal{D}_{Y_S}}(y)}$.

### Classification

Now that we are able to a posterior persistence diagram, we can do this for each digit 0-9. We can then calculate the Wasserstein distance[^1] from the test persistence diagrams to the posterior diagrams for each dimension. Then we sum the distances for each dimension and classify the test image as the class associated with the minimum distance.

[^1]: Also known as Kantorovich-Rubinstein metric, it is a distance function between probability distributions on a metric space $\mathbb{M}$. $W_q(X,Y) = \left( \inf\limits_{\eta: X \rightarrow{} Y} \sum\limits_{x \in X} \|x - \eta(x)\|^p_\infty \right)^{1/p}$. See more [here](https://en.wikipedia.org/wiki/Wasserstein_metric)

## TDA & ML

With our Bayes TDA classification not being as successful as we would've liked, we were also interested in using TDA as a dimension reduction technique to pair with machine learning models. This approach uses the persistence diagram of an image as a predictor. Besides using the grayscale image, we can binarize the image, apply a filter that results in a different grayscale image for the digit. This allows us to generate multiple features for each observation.

### Filtering

The filters we used after binarizing the images were height, radial, dilation, erosion, and density. 

The height filtration assigns a value to each pixel based on its projection onto a chosen direction vector, essentially measuring its "height" from a specific angle. Radial filtration works similarly, instead of assigning a value base on the distance to a vector, it assigns a value to each pixel based on its distance from a chosen center point. Dilation assigns each pixel a value corresponding to its shortest distance to a foreground pixel, where a foreground pixel is a pixel with an intensity of 1. This has the effect of "growing" or "dilating" the digit. Erosion is the inverse of dilation. It works by taking the dilation of the inverted image. This "shrinks" or "erodes" the digit. Lastly, density assigns each pixel a value based on the number of foreground neighbors within a given radius.

After applying the filter to the binarized image, we have a new grayscale image, which we can get a persistence diagram for. Examples of these filters are shown below. For purposes of visibilty, a colored map is used to represent the grayscale values.

```{r filtrations, fig.dim=c(6,6)}
image_index <- which(mnist$train$labels == 8)[100]
image_matrix <- matrix(mnist$train$images[image_index, ], nrow = 28, byrow = TRUE)

binary_image <- ifelse(image_matrix > 0.4, 1, 0)
img_c <- as.cimg(binary_image)
img_c_inv <- as.cimg(1 - binary_image)

coords <- as.matrix(expand.grid(y = 1:28, x = 1:28))

height_filt_td <- matrix(coords %*% c(0, 1), nrow = 28, byrow = TRUE) * binary_image
height_filt_lr <- matrix(coords %*% c(1, 0), nrow = 28, byrow = TRUE) * binary_image

radial_filt_c <- matrix(sqrt(rowSums(sweep(coords, 2, c(14, 14), "-")^2)), nrow = 28, byrow = TRUE) * binary_image
radial_filt_b <- matrix(sqrt(rowSums(sweep(coords, 2, c(14, 28), "-")^2)), nrow = 28, byrow = TRUE) * binary_image

dilation_filt <- as.matrix(distance_transform(img_c, 1))
erosion_filt <- as.matrix(distance_transform(img_c_inv, 1))
density_filt <- as.matrix(boxblur(img_c, 3))

plot_filtration <- function(data_matrix, title) {
  as.data.frame(data_matrix) |>
    mutate(y = row_number()) |>
    pivot_longer(-y, names_to = "x", values_to = "value") |>
    mutate(x = as.integer(gsub("V", "", x))) |>
    ggplot(aes(x = x, y = y, fill = value)) +
    geom_tile() +
    scale_y_reverse() +
    coord_equal() +
    scale_fill_viridis_c(option = "magma", direction = -1) +
    # scale_fill_gradient(low = "white", high = "black", na.value = "white") +
    theme_void() +
    labs(title = title) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"), legend.position = "none")
}

p_orig <- plot_filtration(image_matrix, "Original Grayscale") + scale_fill_gradient(low = "white", high = "black", na.value = "white")
p_bin <- plot_filtration(binary_image, "Binarized") + scale_fill_gradient(low = "white", high = "black", na.value = "white")
p_height_td <- plot_filtration(height_filt_td, "Height (Top-Down)")
p_height_lr <- plot_filtration(height_filt_lr, "Height (Left-Right)")
p_radial_c <- plot_filtration(radial_filt_c, "Radial (Center)")
p_radial_b <- plot_filtration(radial_filt_b, "Radial (Bottom)")
p_dilation <- plot_filtration(dilation_filt, "Dilation")
p_erosion <- plot_filtration(erosion_filt, "Erosion")
p_density <- plot_filtration(density_filt, "Density (r=3)")

(p_orig + p_bin + p_dilation) /
(p_height_td + p_height_lr + p_erosion) /
(p_radial_c + p_radial_b + p_density)
```



# Experiments 

<!-- *Describes the experiments performed, including details on the data used.* -->

## Data Summary

- **Data Composition**:
 - **Training set**: 60,000 images (50% SD-3, 50% SD-7).
 - **Test set**: 10,000 images (originally 60,000, later reduced to 10k).
- **Image Processing**:
 - Resized to **28x28 pixels** with anti-aliasing.
 - Normalized to center of mass alignment.

### EDA

We examined the MNIST training dataset in terms of label distribution, pixel intensity, and overall structure. Label distribution is balanced, with approximately 6,000 examples per digit. We can expect our classifiers not to biased toward any particular class. Pixel intensity analysis reveals that most pixels are zero, reflecting the black background of the images. We also use t-Distributed Stochastic Neighbor Embedding(t-SNE) as developed by [@Rtsne] to provide visualization of the 784-dimensional pixel space in two dimensions. The Figure shows well-separated clusters for each digit, suggesting that the classes are distinguishable and that supervised models can capture these patterns effectively.


## NN dropout

## NN Ridge

## NN Lasso

## Multinomial Logistic

## Bayes TDA

## TDA & ML

# Discussion and Analysis

*Comparing the models*

# Conclusion

<!-- what the project did, what models were used, potential future work -->


\newpage

# References

::: {#refs}
:::


<!-- *Gives properly formatted references to other scholarly work that this work is built on. Note that the references should be scholarly, which means things like refereed conference and journal articles. Importantly, that rules out things like most websites, basic textbooks, and press articles.* -->

<!-- \newpage -->

<!-- # Code Appendix -->

<!-- ```{r ref.label=knitr::all_labels()} -->
<!-- #| echo: true -->
<!-- #| eval: false -->
<!-- ``` -->

\newpage

<!-- # Code Appendix -->

<!-- ```{r appendix-code-lister, echo=FALSE, results='asis'} -->
<!-- all_labels <- knitr::all_labels() -->

<!-- current_chunk_label <- knitr::opts_current$get('label') -->
<!-- all_labels <- all_labels[all_labels != current_chunk_label] -->

<!-- cat("\n") -->

<!-- for (label in all_labels) { -->
<!--  chunk_code <- knitr::knit_code$get(label) -->

<!--  if (length(chunk_code) > 0 && !is.null(chunk_code)) { -->
<!--   cat("```r\n") -->
<!--   cat(paste(chunk_code, collapse = "\n")) -->
<!--   cat("\n```\n") -->
<!--  } -->
<!-- } -->
<!-- ``` -->